{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10971078,"sourceType":"datasetVersion","datasetId":6826538},{"sourceId":11130820,"sourceType":"datasetVersion","datasetId":6942057},{"sourceId":11131605,"sourceType":"datasetVersion","datasetId":6942557},{"sourceId":463846,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":374817,"modelId":395675},{"sourceId":463929,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":374879,"modelId":395729}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport os\nfrom torch.optim.lr_scheduler import StepLR","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:57:57.048110Z","iopub.execute_input":"2025-07-10T10:57:57.048444Z","iopub.status.idle":"2025-07-10T10:58:02.794434Z","shell.execute_reply.started":"2025-07-10T10:57:57.048416Z","shell.execute_reply":"2025-07-10T10:58:02.793453Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#Check if there are available GPUs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmulti_gpu = torch.cuda.device_count() > 1\nprint(f\"ðŸš€ Device: {device} | GPUs Available: {torch.cuda.device_count()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:58:04.296872Z","iopub.execute_input":"2025-07-10T10:58:04.297283Z","iopub.status.idle":"2025-07-10T10:58:04.303670Z","shell.execute_reply.started":"2025-07-10T10:58:04.297252Z","shell.execute_reply":"2025-07-10T10:58:04.302684Z"}},"outputs":[{"name":"stdout","text":"ðŸš€ Device: cuda | GPUs Available: 1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"data_dir = \"/kaggle/input/yolo-crops-v3/yolo_crops\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:58:06.302625Z","iopub.execute_input":"2025-07-10T10:58:06.302932Z","iopub.status.idle":"2025-07-10T10:58:06.306442Z","shell.execute_reply.started":"2025-07-10T10:58:06.302908Z","shell.execute_reply":"2025-07-10T10:58:06.305527Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\n\ndef resize_with_padding(image, target_size=224):\n    w, h = image.size\n    scale = target_size / max(w, h)\n    new_w, new_h = int(w * scale), int(h * scale)\n    image = TF.resize(image, (new_h, new_w))\n    \n    #Calculate padding\n    pad_left = (target_size - new_w) // 2\n    pad_top = (target_size - new_h) // 2\n    pad_right = target_size - new_w - pad_left\n    pad_bottom = target_size - new_h - pad_top\n    \n    #Add black padding (0)\n    image = TF.pad(image, (pad_left, pad_top, pad_right, pad_bottom), fill=0)\n    return image\n\n\ndata_transforms = {\n    \"train\": transforms.Compose([\n        transforms.Lambda(lambda img: resize_with_padding(img, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.RandomRotation(15),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    \"val\": transforms.Compose([\n        transforms.Lambda(lambda img: resize_with_padding(img, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:58:13.184253Z","iopub.execute_input":"2025-07-10T10:58:13.184552Z","iopub.status.idle":"2025-07-10T10:58:13.191652Z","shell.execute_reply.started":"2025-07-10T10:58:13.184531Z","shell.execute_reply":"2025-07-10T10:58:13.190727Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#Load labels and images\ndataset = datasets.ImageFolder(root=data_dir, transform=data_transforms[\"train\"])\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n#Apply tranforms\ntrain_dataset.dataset.transform = data_transforms[\"train\"]\nval_dataset.dataset.transform = data_transforms[\"val\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:58:16.954354Z","iopub.execute_input":"2025-07-10T10:58:16.954684Z","iopub.status.idle":"2025-07-10T10:59:06.904492Z","shell.execute_reply.started":"2025-07-10T10:58:16.954656Z","shell.execute_reply":"2025-07-10T10:59:06.903746Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#DataLoader\nbatch_size = 128\nnum_workers = 4 if device == \"cuda\" else 2\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:59:09.485112Z","iopub.execute_input":"2025-07-10T10:59:09.485391Z","iopub.status.idle":"2025-07-10T10:59:09.489547Z","shell.execute_reply.started":"2025-07-10T10:59:09.485368Z","shell.execute_reply":"2025-07-10T10:59:09.488718Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torchvision import datasets, models, transforms\nimport torch.amp  # Pentru mixed precision\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#Init with pretrained ResNet\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, len(dataset.classes))  # AsigurÄƒ-te cÄƒ 'dataset.classes' este corect definit\n\nmodel = model.to(device)\n\n#Definie Loss Function and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = StepLR(optimizer, step_size=3, gamma=0.1)  # Reduce lr at every 3 epochs\n\n# Mixed Precision Training\nscaler = torch.amp.GradScaler()\n\nnum_epochs = 10\n\n#Training\nfor epoch in range(num_epochs):\n    print(\"=\" * 50)\n    print(f\"START Epoch [{epoch+1}/{num_epochs}]\")\n    print(\"=\" * 50)\n\n    model.train()  #Model in train mode\n    running_loss = 0.0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n        optimizer.zero_grad()  # Reset gradients\n\n        #Mixed Precision\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n        #Backpropagation with mixed precision\n        scaler.scale(loss).backward()  #Calculate gradients\n        scaler.step(optimizer)  #Optimizer step\n        scaler.update()\n\n        running_loss += loss.item()  #Add loss for this batch\n\n    scheduler.step()  #Update scheduler for lr\n\n    #Eval on validation set\n    model.eval()  #Model in evaluation set\n    val_loss, correct, total = 0.0, 0, 0\n\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n            with torch.amp.autocast(device_type='cuda'):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n            val_loss += loss.item()  #Add loss for this batchh\n            _, preds = torch.max(outputs, 1)  #Predictions\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    val_acc = correct / total  #Calculate Accuracy\n    print(\"-\" * 50)\n    print(f\"Epoch [{epoch+1}/{num_epochs}] COMPLETED\")\n    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n    print(f\"Val Loss: {val_loss/len(val_loader):.4f} | Accuracy: {val_acc:.4%}\")\n    print(\"=\" * 50)\n\n    #Save model each epoch\n    model_save_path = f\"resnet_fruits_epoch_{epoch+1}.pth\"\n    torch.save(model.state_dict(), model_save_path)\n    print(f\"Model Saved: {model_save_path}\")\n\n#Save final model\nmodel_save_path_final = \"resnet_fruits_final.pth\"\ntorch.save(model.state_dict(), model_save_path_final)\nprint(f\"Final Model Saved: {model_save_path_final}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#Load the pre-trained ResNet50 model and replace the classification head\nmodel = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 30)\n\n#Load the weights from the previously trained model\nmodel.load_state_dict(torch.load(\"/kaggle/input/resnet_fruits_best_6/pytorch/default/1/resnet_fruits_epoch_6.pth\", map_location=device))\nmodel = model.to(device)\nprint(\"Model loaded!\")\n\n#Freeze all layers except for the final fully-connected (fc) layer\nfor name, param in model.named_parameters():\n    param.requires_grad = name.startswith(\"fc\")\n\n#Define optimizer for the final layer only with low learning rate\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4, weight_decay=1e-4)\ncriterion = nn.CrossEntropyLoss()\n\n#Learning rate scheduler based on validation accuracy\nscheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.3, patience=1, threshold=0.002)\nscaler = torch.amp.GradScaler()\n\nnum_epochs = 3\n\n#Fine-tuning loop (only for the final layer)\nfor epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    model.train()\n    train_loss = 0.0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        with torch.amp.autocast(device_type='cuda'):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        train_loss += loss.item()\n\n    #Evaluation on validation set\n    model.eval()\n    val_loss, correct, total = 0.0, 0, 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            with torch.amp.autocast(device_type='cuda'):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    val_acc = correct / total\n    scheduler.step(val_acc)\n\n    print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n    print(f\"Val Loss: {val_loss/len(val_loader):.4f} | Accuracy: {val_acc:.4%}\")\n\n    #Save model after each epoch\n    torch.save(model.state_dict(), f\"resnet_fruits_finetuned_fc_only_epoch_{epoch+1}.pth\")\n\n#Save the final fine-tuned model\ntorch.save(model.state_dict(), \"resnet_fruits_finetuned_fc_only_best.pt\")\nprint(\"Fine-tuning completed and model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T14:29:06.979370Z","iopub.execute_input":"2025-07-08T14:29:06.979769Z","iopub.status.idle":"2025-07-08T14:39:02.229212Z","shell.execute_reply.started":"2025-07-08T14:29:06.979741Z","shell.execute_reply":"2025-07-08T14:39:02.228011Z"}},"outputs":[{"name":"stdout","text":"âœ… Model loaded!\n\nðŸ”¥ Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-57-05ab3a4c71fa>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/resnet_fruits_best_6/pytorch/default/1/resnet_fruits_epoch_6.pth\", map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"ðŸ“‰ Train Loss: 0.0073\nðŸ“Š Val Loss: 0.1161 | Accuracy: 96.8119%\n\nðŸ”¥ Epoch 2/5\nðŸ“‰ Train Loss: 0.0066\nðŸ“Š Val Loss: 0.1191 | Accuracy: 96.8119%\n\nðŸ”¥ Epoch 3/5\nðŸ“‰ Train Loss: 0.0063\nðŸ“Š Val Loss: 0.1224 | Accuracy: 96.7395%\n\nðŸ”¥ Epoch 4/5\nðŸ“‰ Train Loss: 0.0056\nðŸ“Š Val Loss: 0.1204 | Accuracy: 96.8326%\n\nðŸ”¥ Epoch 5/5\nðŸ“‰ Train Loss: 0.0058\nðŸ“Š Val Loss: 0.1203 | Accuracy: 96.8844%\nâœ… Fine-tuning completed and model saved!\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\naccuracy = 100 * correct / total\nprint(f\"Accuracy on validation set: {accuracy:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validation for Trained model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T10:59:28.982340Z","iopub.execute_input":"2025-07-10T10:59:28.982674Z","iopub.status.idle":"2025-07-10T10:59:28.986571Z","shell.execute_reply.started":"2025-07-10T10:59:28.982639Z","shell.execute_reply":"2025-07-10T10:59:28.985715Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"state_dict = torch.load(\"/kaggle/input/resnet_fruits_best_6/pytorch/default/1/resnet_fruits_epoch_6.pth\", map_location=device)\nmodel.load_state_dict(state_dict)\nmodel = model.to(device)\nmodel.eval()\nprint(\"Model loaded successfully from state_dict!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true, y_pred = [], []\n\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = val_dataset.dataset.classes  # obÈ›ine numele claselor\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\nplt.title(\"Matricea de Confuzie\")\nplt.xlabel(\"Etichete prezise\")\nplt.ylabel(\"Etichete reale\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\ndf_report = pd.DataFrame(report).transpose()\n\nprint(df_report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = accuracy_score(y_true, y_pred)\nprint(f\"AcurateÈ›e globalÄƒ: {acc:.4%}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f1_scores = df_report.iloc[:-3][\"f1-score\"]\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=f1_scores.index, y=f1_scores.values, color='skyblue')\nplt.xticks(rotation=90)\nplt.ylabel(\"F1-score\")\nplt.title(\"F1-score per clasÄƒ\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validation for Fine-Tuned model","metadata":{}},{"cell_type":"code","source":"state_dict = torch.load(\"/kaggle/input/model_finetuned/pytorch/default/1/resnet_fruits_finetuned_fc_only_epoch_4.pth\", map_location=device)\nmodel.load_state_dict(state_dict)\nmodel = model.to(device)\nmodel.eval()\nprint(\"Model loaded successfully from state_dict!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_true, y_pred = [], []\n\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T11:02:17.530999Z","iopub.execute_input":"2025-07-10T11:02:17.531231Z","iopub.status.idle":"2025-07-10T11:02:41.495161Z","shell.execute_reply.started":"2025-07-10T11:02:17.531213Z","shell.execute_reply":"2025-07-10T11:02:41.494230Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"class_names = val_dataset.dataset.classes  # obÈ›ine numele claselor\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\nplt.title(\"Matricea de Confuzie\")\nplt.xlabel(\"Etichete prezise\")\nplt.ylabel(\"Etichete reale\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\ndf_report = pd.DataFrame(report).transpose()\n\nprint(df_report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = accuracy_score(y_true, y_pred)\nprint(f\"AcurateÈ›e globalÄƒ: {acc:.4%}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f1_scores = df_report.iloc[:-3][\"f1-score\"]\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=f1_scores.index, y=f1_scores.values, color='skyblue')\nplt.xticks(rotation=90)\nplt.ylabel(\"F1-score\")\nplt.title(\"F1-score per clasÄƒ\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}