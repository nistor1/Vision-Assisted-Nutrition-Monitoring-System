{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ‚úÖ Use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:02.220679700Z",
     "start_time": "2025-03-24T14:22:02.176871200Z"
    }
   },
   "id": "f72f7412dd0f945c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# ‚úÖ Path to trained YOLO model\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# yolo_model_path = \"E:/anul 4/LICENTA_NISTOR_IOAN_GABRIEL/runs/detect/train/weights/best.pt\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m yolo_model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mE:/anul 4/LICENTA INVATARE/runs/detect_roi/train3/weights/best.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 5\u001B[0m yolo_model \u001B[38;5;241m=\u001B[39m YOLO(yolo_model_path)\n\u001B[0;32m      6\u001B[0m yolo_model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# ‚úÖ Path to trained ResNet-50 model\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'YOLO' is not defined"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Path to trained YOLO model\n",
    "# yolo_model_path = \"E:/anul 4/LICENTA_NISTOR_IOAN_GABRIEL/runs/detect/train/weights/best.pt\"\n",
    "yolo_model_path = \"E:/anul 4/LICENTA INVATARE/runs/detect_roi/train3/weights/best.pt\"\n",
    "\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "yolo_model.eval()\n",
    "\n",
    "# ‚úÖ Path to trained ResNet-50 model\n",
    "num_classes = 30 \n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
    "resnet.load_state_dict(torch.load(\"E:/anul 4/LICENTA INVATARE/runs/detect_roi/train_resnet_fruits/FineTunedResnet/resnet_fruits_epoch_1.pth\", map_location=device))\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# ‚úÖ ResNet Transform\n",
    "resnet_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# asta poate\n",
    "#resnet_transform = transforms.Compose([\n",
    " #   transforms.Resize(224),\n",
    "  #  transforms.Pad(padding),\n",
    "   # transforms.CenterCrop(224),\n",
    "   # transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "     #                    std=[0.229, 0.224, 0.225]),\n",
    "#])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-13T14:37:34.130058700Z",
     "start_time": "2025-05-13T14:37:33.593583500Z"
    }
   },
   "id": "560772b81f5f838d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def detect_and_crop(image_path, model_yolo):\n",
    "    \"\"\"Detect objects in an image and return a list of cropped images.\"\"\"\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    # ‚úÖ Run YOLO on the image\n",
    "    results = model_yolo(image_path)\n",
    "    cropped_images = []\n",
    "\n",
    "    for result in results:\n",
    "        for bbox, cls in zip(result.boxes.xywh, result.boxes.cls):\n",
    "            x_c, y_c, w, h = bbox\n",
    "            x_min = int((x_c - w / 2))\n",
    "            y_min = int((y_c - h / 2))\n",
    "            x_max = int((x_c + w / 2))\n",
    "            y_max = int((y_c + h / 2))\n",
    "\n",
    "            # ‚úÖ Crop the object from the image\n",
    "            cropped_img = image.crop((x_min, y_min, x_max, y_max))\n",
    "            cropped_images.append(cropped_img)\n",
    "            \n",
    "    if(len(cropped_images) > 0):\n",
    "        print(f\"‚úÖ Detected {len(cropped_images)} objects.\")\n",
    "        return cropped_images \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No detection! Use the entire image.\")\n",
    "        return image \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:05.901328800Z",
     "start_time": "2025-03-24T14:22:05.893840Z"
    }
   },
   "id": "cb20c05b86d5b805"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def classify_with_resnet(image, model_resnet, class_names):\n",
    "    \"\"\"Receive an image and return the predicted class.\"\"\"\n",
    "    \n",
    "    image = resnet_transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model_resnet(image)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    return class_names[predicted_class]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:05.924334700Z",
     "start_time": "2025-03-24T14:22:05.915331300Z"
    }
   },
   "id": "4a328cb4a07eee85"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 E:\\anul 4\\LICENTA_NISTOR_IOAN_GABRIEL\\datasets\\food.v1i.yolov11\\test3\\14.jpg: 640x480 4 rois, 2223.1ms\n",
      "Speed: 100.7ms preprocess, 2223.1ms inference, 52.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "‚úÖ Detected 4 objects.\n",
      "üéØ Predicted class for object 1: 21\n",
      "üéØ Predicted class for object 2: 4\n",
      "üéØ Predicted class for object 3: 23\n",
      "üéØ Predicted class for object 4: 2\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Set the path to the test image\n",
    "test_image_path = \"E:/anul 4/LICENTA_NISTOR_IOAN_GABRIEL/datasets/food.v1i.yolov11/test3/14.jpg\"\n",
    "\n",
    "cropped_images = detect_and_crop(test_image_path, yolo_model)\n",
    "\n",
    "for i, cropped_image in enumerate(cropped_images):\n",
    "    predicted_label = classify_with_resnet(cropped_image, resnet, [str(i) for i in range(num_classes)])\n",
    "    print(f\"üéØ Predicted class for object {i+1}: {predicted_label}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T17:08:24.884616400Z",
     "start_time": "2025-03-24T17:08:20.688499Z"
    }
   },
   "id": "4ae9d5c57aa5a929"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "#!yolo val model=\"E:/anul 4/LICENTA INVATARE/runs/detect/train2/weights/best.pt\" data=\"E:/anul #4/licenta/dataset/FruitsAndVegetablesFinal/data.yaml\"         \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:09.009868900Z",
     "start_time": "2025-03-24T14:22:08.999755Z"
    }
   },
   "id": "ef37f423a868e6d0"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:09.010868200Z",
     "start_time": "2025-03-24T14:22:09.006861900Z"
    }
   },
   "id": "10aa9e2befe0d24"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:09.026911500Z",
     "start_time": "2025-03-24T14:22:09.013382900Z"
    }
   },
   "id": "12de41e80bb6422b"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-24T14:22:09.039910300Z",
     "start_time": "2025-03-24T14:22:09.020905800Z"
    }
   },
   "id": "1f53c41275bddf1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
